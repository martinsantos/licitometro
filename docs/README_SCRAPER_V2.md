# LICITOMETRO - Gran Scraper v2.0

## Resumen Ejecutivo

Se ha implementado una arquitectura completa de scraping escalable para LICITOMETRO con las siguientes capacidades:

âœ… **Scheduling AutomÃ¡tico** - EjecuciÃ³n periÃ³dica segÃºn cron  
âœ… **URLs Ãšnicas CanÃ³nicas** - Cada licitaciÃ³n tiene URL directa al proceso  
âœ… **DeduplicaciÃ³n Inteligente** - Fusiona licitaciones duplicadas de mÃºltiples fuentes  
âœ… **Tracking Completo** - Monitoreo de cada ejecuciÃ³n con mÃ©tricas  
âœ… **Arquitectura Escalable** - Lista para extender a otras provincias  

---

## ðŸ—ï¸ Arquitectura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         SCHEDULER (APScheduler)                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚  â”‚ COMPR.AR Mza â”‚  â”‚ BoletÃ­n Mza  â”‚  â”‚ AYSAM        â”‚  ...             â”‚
â”‚  â”‚ Cada 4 horas â”‚  â”‚ Diario 6am   â”‚  â”‚ Por definir  â”‚                  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                â”‚                â”‚
          â–¼                â–¼                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        SCRAPERS (Async)                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  â€¢ ExtracciÃ³n de datos                                           â”‚   â”‚
â”‚  â”‚  â€¢ GeneraciÃ³n de content_hash                                    â”‚   â”‚
â”‚  â”‚  â€¢ ResoluciÃ³n de URLs canÃ³nicas                                  â”‚   â”‚
â”‚  â”‚  â€¢ DetecciÃ³n de calidad de URL (direct/proxy/partial)           â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
                                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       PIPELINE DE PROCESAMIENTO                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚  â”‚ Normalizar   â”‚â†’ â”‚ Deduplicar   â”‚â†’ â”‚ Enriquecer   â”‚                  â”‚
â”‚  â”‚ datos        â”‚  â”‚ (fuzzy match)â”‚  â”‚ URLs         â”‚                  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           STORAGE                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  MongoDB                                                         â”‚   â”‚
â”‚  â”‚  â”œâ”€â”€ licitaciones (con canonical_url, source_urls, url_quality) â”‚   â”‚
â”‚  â”‚  â”œâ”€â”€ scraper_configs (con schedule cron)                        â”‚   â”‚
â”‚  â”‚  â””â”€â”€ scraper_runs (tracking de ejecuciones)                     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸ“‹ Componentes Implementados

### 1. Models (`backend/models/`)

| Archivo | Cambios |
|---------|---------|
| `scraper_run.py` | NUEVO - Modelo para tracking de ejecuciones |
| `licitacion.py` | ACTUALIZADO - Campos: `canonical_url`, `source_urls`, `url_quality`, `content_hash` |
| `__init__.py` | ACTUALIZADO - Exporta ScraperRun |

### 2. Services (`backend/services/`)

| Archivo | FunciÃ³n |
|---------|---------|
| `scheduler_service.py` | Scheduling con APScheduler, tracking de ejecuciones |
| `deduplication_service.py` | DeduplicaciÃ³n fuzzy matching + merge de datos |
| `url_resolver.py` | ResoluciÃ³n y clasificaciÃ³n de URLs |
| `__init__.py` | Exporta todos los servicios |

### 3. Routers (`backend/routers/`)

| Archivo | Endpoints |
|---------|-----------|
| `scheduler.py` | `/api/scheduler/*` - Control de scheduling |
| `licitaciones.py` | `/api/licitaciones/{id}/redirect`, `/urls`, `/deduplicate` |
| `server.py` | Auto-inicio de scheduler |

### 4. Scrapers (`backend/scrapers/`)

| Archivo | Cambios |
|---------|---------|
| `mendoza_compra.py` | Genera `content_hash`, `canonical_url`, `source_urls` |

---

## ðŸš€ API Endpoints Nuevos

### Scheduler
```
POST   /api/scheduler/start
POST   /api/scheduler/stop
GET    /api/scheduler/status
GET    /api/scheduler/jobs
POST   /api/scheduler/trigger/{scraper_name}
GET    /api/scheduler/runs
GET    /api/scheduler/runs/{run_id}
GET    /api/scheduler/runs/{run_id}/logs
GET    /api/scheduler/stats
```

### Licitaciones (URLs)
```
GET    /api/licitaciones/{id}/redirect      # RedirecciÃ³n a URL canÃ³nica
GET    /api/licitaciones/{id}/urls          # Todas las URLs disponibles
POST   /api/licitaciones/{id}/resolve-url   # Resolver URL especÃ­fica
GET    /api/licitaciones/stats/url-quality  # EstadÃ­sticas de calidad
POST   /api/licitaciones/deduplicate        # Ejecutar deduplicaciÃ³n
```

---

## ðŸ“Š Flujo de Datos

### URL Quality Hierarchy

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    URL QUALITY                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ direct  â†’ VistaPreviaPliegoCiudadano.aspx (URL Ãºnica)     â”‚
â”‚ proxy   â†’ /api/comprar/proceso/open (auto-submit form)    â”‚
â”‚ partial â†’ Compras.aspx (solo lista)                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Deduplication Strategy

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              DEDUPLICATION MATCHING                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1. Expediente igual          â†’ Match 100%                 â”‚
â”‚ 2. NÃºmero de proceso igual   â†’ Match 100%                 â”‚
â”‚ 3. Content hash igual        â†’ Match 100%                 â”‚
â”‚ 4. TÃ­tulo similar >85%       â†’ Match fuzzy                â”‚
â”‚    + OrganizaciÃ³n igual                                   â”‚
â”‚    + Fechas cercanas (<7 dÃ­as)                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸ”§ InstalaciÃ³n

### 1. Instalar Dependencias

```bash
cd /Applications/um/licitometro
pip install -r backend/requirements.txt
```

### 2. Verificar InstalaciÃ³n

```bash
python3 scripts/verify_scraper_v2.py
```

### 3. Iniciar Servidor

```bash
cd backend
python server.py
```

El scheduler se inicia automÃ¡ticamente.

---

## ðŸ“ˆ Uso

### Ver Estado del Scheduler

```bash
curl http://localhost:8001/api/scheduler/status
```

Respuesta:
```json
{
  "running": true,
  "jobs": [
    {
      "id": "scraper_COMPR.AR Mendoza",
      "name": "COMPR.AR Mendoza",
      "next_run_time": "2026-02-05T13:00:00-03:00",
      "trigger": "cron[hour='7,13,19', minute='0']"
    }
  ]
}
```

### Ejecutar Scraper Manualmente

```bash
curl -X POST http://localhost:8001/api/scheduler/trigger/COMPR.AR%20Mendoza
```

### Ver Ejecuciones Recientes

```bash
curl http://localhost:8001/api/scheduler/runs
```

Respuesta:
```json
[
  {
    "id": "uuid",
    "scraper_name": "COMPR.AR Mendoza",
    "status": "success",
    "items_found": 85,
    "items_saved": 12,
    "items_updated": 73,
    "urls_with_pliego": 23,
    "duration_seconds": 245.3,
    "started_at": "2026-02-05T07:00:00",
    "ended_at": "2026-02-05T07:04:05"
  }
]
```

### Ejecutar DeduplicaciÃ³n

```bash
curl -X POST "http://localhost:8001/api/licitaciones/deduplicate?jurisdiccion=Mendoza"
```

### Ver EstadÃ­sticas de URLs

```bash
curl http://localhost:8001/api/licitaciones/stats/url-quality
```

Respuesta:
```json
{
  "total": 156,
  "by_quality": {
    "direct": 45,
    "proxy": 89,
    "partial": 22
  },
  "percentages": {
    "direct": 28.85,
    "proxy": 57.05,
    "partial": 14.1
  }
}
```

---

## ðŸ“ Archivos de DocumentaciÃ³n

| Archivo | Contenido |
|---------|-----------|
| `docs/PLAN_GRAN_SCRAPER.md` | Plan detallado de arquitectura |
| `docs/IMPLEMENTACION_SCRAPER_V2.md` | GuÃ­a de implementaciÃ³n tÃ©cnica |
| `docs/PROGRESS_COMPRAR_MZA.md` | Estado actual COMPR.AR Mendoza |
| `scripts/verify_scraper_v2.py` | Script de verificaciÃ³n |

---

## ðŸŽ¯ PrÃ³ximos Pasos

### Inmediatos (Esta semana)
1. âœ… Testing del scheduler
2. âœ… Optimizar captura de URLs PLIEGO
3. âœ… Agregar scrapers: AYSAM, OSEP, UNCuyo

### Corto plazo (PrÃ³ximas 2 semanas)
4. Dashboard de monitoreo en frontend
5. Sistema de alertas (email/webhook)
6. Escalar a otras provincias (Buenos Aires, CABA, CÃ³rdoba, Santa Fe)

### Mediano plazo (PrÃ³ximo mes)
7. IntegraciÃ³n con Elasticsearch para bÃºsquedas avanzadas
8. Sistema de notificaciones a usuarios
9. API pÃºblica para consumo de datos

---

## ðŸ“ž Soporte

Para reportar problemas o sugerir mejoras:
- Revisar logs: `backend.log`, `comprar.log`
- Verificar scraper runs: `/api/scheduler/runs`
- Ejecutar verificaciÃ³n: `python3 scripts/verify_scraper_v2.py`

---

*VersiÃ³n: 2.0*  
*Fecha: 2026-02-05*  
*Autor: Equipo LicitÃ³metro*
